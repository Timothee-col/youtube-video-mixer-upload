"""
Module d'EXTRACTION de clips vid√©o
=====================================
Ce module g√®re l'extraction des meilleurs moments depuis les vid√©os sources.

Fonctions principales :
- extract_best_clips_with_face : Extrait les meilleurs clips avec d√©tection faciale
- resize_and_center_vertical : Redimensionne au format 9:16
- add_logo_overlay : Ajoute un logo sur la vid√©o
- add_audio_to_video : Ajoute une piste audio
- add_tagline : Ajoute une vid√©o tagline
"""
import cv2
import numpy as np
import streamlit as st
import random
from moviepy.editor import (
    VideoFileClip, concatenate_videoclips, CompositeVideoClip, 
    ImageClip, AudioFileClip, afx
)
from PIL import Image
from typing import List, Dict, Optional, Tuple
from constants import VIDEO_FORMAT, DEFAULT_SETTINGS, UI_MESSAGES, IS_RAILWAY
from video_analyzer import analyze_video_segments_with_face
from face_detector import get_face_regions_for_crop
from text_detector import detect_text_regions, remove_text_with_crop, remove_text_with_inpainting

def resize_and_center_vertical(
    clip: VideoFileClip,
    remove_text_method: Optional[str] = None,
    text_net: Optional[cv2.dnn_Net] = None,
    face_regions: Optional[List[Dict]] = None,
    use_lanczos: bool = False  # D√©sactiv√© par d√©faut pour Railway
) -> VideoFileClip:
    """
    Redimensionne la vid√©o au format vertical 9:16 avec crop intelligent
    
    Args:
        clip: Clip vid√©o √† traiter
        remove_text_method: M√©thode de suppression de texte
        text_net: Mod√®le de d√©tection de texte
        face_regions: R√©gions de visages pour le crop intelligent
        use_lanczos: Utiliser Lanczos pour un resize plus net
    
    Returns:
        VideoFileClip: Clip redimensionn√©
    """
    # VALIDATION CRITIQUE en entr√©e
    if clip is None:
        st.error("‚ùå ERREUR FATALE: clip None pass√© √† resize_and_center_vertical")
        return None
    
    if not hasattr(clip, 'size') or not hasattr(clip, 'get_frame'):
        st.error(f"‚ùå ERREUR: clip invalide pass√© √† resize_and_center_vertical (type: {type(clip)})")
        return None
    
    st.info(f"üîÑ resize_and_center_vertical: d√©but traitement clip (dur√©e: {getattr(clip, 'duration', 'N/A')}s)")
    
    target_width = VIDEO_FORMAT['width']
    target_height = VIDEO_FORMAT['height']
    target_ratio = VIDEO_FORMAT['ratio']
    
    # Si on doit enlever le texte, le faire frame par frame
    if remove_text_method and text_net is not None:
        def process_frame(frame):
            text_regions = detect_text_regions(frame, text_net)
            
            if text_regions:
                if remove_text_method == "crop":
                    frame = remove_text_with_crop(frame, text_regions)
                elif remove_text_method == "inpaint":
                    frame = remove_text_with_inpainting(frame, text_regions)
            
            return frame
        
        clip = clip.fl_image(process_frame)
    
    # Dimensions originales
    orig_w, orig_h = clip.size
    orig_ratio = orig_w / orig_h
    
    # Fonction de resize avec Lanczos
    def apply_lanczos_resize(frame):
        """
        Applique un resize Lanczos de haute qualit√© √† chaque frame
        """
        # Validation pour √©viter les erreurs avec des frames None
        if frame is None:
            st.error("‚ùå Frame None d√©tect√© dans Lanczos resize!")
            # Retourner une frame noire de la bonne taille
            return np.zeros((target_height, target_width, 3), dtype=np.uint8)
        
        try:
            # V√©rifier que la frame a la bonne forme
            if not isinstance(frame, np.ndarray) or len(frame.shape) != 3:
                st.error(f"‚ùå Frame invalide: type={type(frame)}, shape={getattr(frame, 'shape', 'N/A')}")
                return np.zeros((target_height, target_width, 3), dtype=np.uint8)
            
            # Utiliser cv2.INTER_LANCZOS4 pour la meilleure qualit√©
            result = cv2.resize(frame, (target_width, target_height), interpolation=cv2.INTER_LANCZOS4)
            return result
        except Exception as e:
            st.error(f"‚ùå Erreur Lanczos resize: {str(e)}")
            return np.zeros((target_height, target_width, 3), dtype=np.uint8)
    
    # Si d√©j√† au bon ratio
    if abs(orig_ratio - target_ratio) < 0.1:
        if use_lanczos:
            clip = clip.fl_image(apply_lanczos_resize)
        else:
            clip = clip.resize((target_width, target_height))
    
    # Si horizontal (plus large que haut)
    elif orig_ratio > target_ratio:
        new_height = orig_h
        new_width = int(orig_h * target_ratio)
        
        # Centrer sur les visages si disponibles
        if face_regions and len(face_regions) > 0:
            face_centers_x = [(r['x'] + r['width']//2) for r in face_regions]
            avg_x = sum(face_centers_x) // len(face_centers_x)
            x_start = avg_x - new_width // 2
            x_start = max(0, min(x_start, orig_w - new_width))
        else:
            x_start = (orig_w - new_width) // 2
        
        # Cropper d'abord
        clip = clip.crop(x1=x_start, y1=0, x2=x_start + new_width, y2=orig_h)
        
        # Puis resize avec Lanczos ou m√©thode standard
        if use_lanczos:
            clip = clip.fl_image(apply_lanczos_resize)
        else:
            clip = clip.resize((target_width, target_height))
    
    # Si trop vertical
    else:
        new_width = orig_w
        new_height = int(orig_w / target_ratio)
        
        # Garder les visages dans le cadre
        if face_regions and len(face_regions) > 0:
            face_tops = [r['y'] for r in face_regions]
            face_bottoms = [r['y'] + r['height'] for r in face_regions]
            min_y = min(face_tops)
            max_y = max(face_bottoms)
            
            face_center_y = (min_y + max_y) // 2
            y_start = face_center_y - new_height // 2
            
            if y_start < 0:
                y_start = 0
            elif y_start + new_height > orig_h:
                y_start = orig_h - new_height
            
            if max_y - min_y > new_height * 0.8:
                y_start = max(0, min_y - int(new_height * 0.1))
        else:
            y_start = (orig_h - new_height) // 2
        
        # Cropper d'abord
        clip = clip.crop(x1=0, y1=y_start, x2=orig_w, y2=y_start + new_height)
        
        # Puis resize avec Lanczos ou m√©thode standard
        if use_lanczos:
            clip = clip.fl_image(apply_lanczos_resize)
        else:
            clip = clip.resize((target_width, target_height))
    
    # Retirer l'audio
    clip = clip.without_audio()
    
    return clip

def extract_best_clips_with_face(
    video_path: str,
    target_face_encoding: Optional[np.ndarray] = None,
    max_clips_per_video: int = 3,
    min_clip_duration: float = 3,
    max_clip_duration: float = 8,
    video_index: int = 0,
    analysis_mode: str = "üéØ Pr√©cis (3-5 min)",
    avoid_text: bool = False,
    text_net: Optional[cv2.dnn_Net] = None,
    face_detection_only: bool = False,
    remove_text_method: Optional[str] = None,
    smart_crop: bool = True,
    use_lanczos: bool = False,  # D√©sactiv√© par d√©faut, surtout sur Railway
    exclude_first_seconds: float = 0,
    face_threshold: float = 0.4
) -> List[VideoFileClip]:
    """
    Extrait les meilleurs clips d'une vid√©o
    
    Args:
        video_path: Chemin de la vid√©o
        target_face_encoding: Encoding du visage cible
        max_clips_per_video: Nombre max de clips
        min_clip_duration: Dur√©e min d'un clip
        max_clip_duration: Dur√©e max d'un clip
        video_index: Index de la vid√©o
        analysis_mode: Mode d'analyse
        avoid_text: √âviter le texte
        text_net: Mod√®le de d√©tection de texte
        face_detection_only: Extraire uniquement avec visage cible
        remove_text_method: M√©thode de suppression de texte
        smart_crop: Crop intelligent sur les visages
    
    Returns:
        List[VideoFileClip]: Liste des clips extraits
    """
    video = VideoFileClip(video_path)
    duration = video.duration
    
    # Analyser la vid√©o
    best_segments = analyze_video_segments_with_face(
        video_path,
        target_face_encoding=target_face_encoding,
        min_clip_duration=min_clip_duration,
        max_clip_duration=max_clip_duration,
        video_index=video_index,
        analysis_mode=analysis_mode,
        avoid_text=avoid_text,
        text_net=text_net,
        remove_text_method=remove_text_method,
        exclude_first_seconds=exclude_first_seconds,
        face_threshold=face_threshold
    )
    
    clips = []
    
    # OPTIMISATIONS SP√âCIFIQUES RAILWAY
    if IS_RAILWAY:
        # R√©duire le nombre de segments √† analyser sur Railway
        max_clips_per_video = min(max_clips_per_video, 2)  # Max 2 clips par vid√©o sur Railway
        st.info(f"üöÇ Mode Railway: Limitation √† {max_clips_per_video} clips par vid√©o")
    else:
        st.info(f"üíª Mode local: {max_clips_per_video} clips par vid√©o maximum")
    
    for i, segment in enumerate(best_segments[:max_clips_per_video]):
        # Filtrer si n√©cessaire
        if face_detection_only and target_face_encoding is not None:
            if not segment.get('has_target_face', False):
                st.info(f"üö´ Segment {i+1} ignor√©: pas de visage cible")
                continue
        
        try:
            # V√©rifications
            if segment['start'] >= duration:
                st.warning(f"Clip {i+1} ignor√©: d√©but apr√®s la fin de la vid√©o")
                continue
            
            if segment['end'] > duration:
                segment['end'] = duration
            
            actual_start = max(0, segment['start'])
            actual_end = min(segment['end'], duration)
            
            if actual_end > actual_start and actual_end - actual_start >= 1:
                st.info(f"üé¨ Cr√©ation subclip {i+1}: {actual_start:.1f}s √† {actual_end:.1f}s")
                clip = video.subclip(actual_start, actual_end)
                
                # VALIDATION CRITIQUE du clip cr√©√©
                if clip is None:
                    st.error(f"‚ùå ERREUR: video.subclip() a retourn√© None pour clip {i+1}")
                    continue
                    
                st.success(f"‚úÖ Subclip {i+1} cr√©√© avec succ√®s (dur√©e: {clip.duration:.1f}s)")
                
                # D√©tection des visages pour le crop intelligent
                face_regions = []
                if smart_crop:
                    try:
                        st.info(f"üéØ Test d'acc√®s frame pour crop intelligent clip {i+1}...")
                        frame = clip.get_frame(0.1)
                        if frame is None:
                            st.warning(f"‚ö†Ô∏è Frame None retourn√©e par clip {i+1}.get_frame(0.1)")
                        else:
                            st.success(f"‚úÖ Frame OK pour clip {i+1}, shape: {frame.shape}")
                            face_regions = get_face_regions_for_crop(frame, target_face_encoding, face_threshold)
                            
                            if face_regions:
                                st.success(f"   üéØ {len(face_regions)} visage(s) d√©tect√©(s) pour le crop intelligent")
                    except Exception as e:
                        st.error(f"   ‚ùå ERREUR crop intelligent clip {i+1}: {str(e)}")
                        st.warning(f"   ‚ö†Ô∏è Crop intelligent d√©sactiv√© pour clip {i+1}")
                
                # Convertir au format vertical
                try:
                    # V√©rifier que le clip est valide avant le resize
                    if clip is None or not hasattr(clip, 'get_frame'):
                        st.error(f"‚ùå Clip {i+1} invalide avant resize")
                        continue
                    
                    # Tester l'acc√®s √† une frame pour valider le clip
                    try:
                        test_frame = clip.get_frame(0)
                        if test_frame is None:
                            st.error(f"‚ùå Clip {i+1} retourne des frames None")
                            clip.close()
                            continue
                    except Exception as e:
                        st.error(f"‚ùå Impossible d'acc√©der aux frames du clip {i+1}: {str(e)}")
                        clip.close()
                        continue
                    
                    clip = resize_and_center_vertical(
                        clip,
                        remove_text_method=remove_text_method if remove_text_method else None,
                        text_net=text_net if remove_text_method else None,
                        face_regions=face_regions if smart_crop else None,
                        use_lanczos=use_lanczos
                    )
                    
                    # HARMONISATION DES FORMATS pour vid√©os upload√©es mixtes
                    if clip is not None:
                        try:
                            # Standardiser le FPS au format cible
                            target_fps = VIDEO_FORMAT['fps']
                            if hasattr(clip, 'fps') and clip.fps != target_fps:
                                st.info(f"üîÑ Harmonisation FPS clip {i+1}: {clip.fps} ‚Üí {target_fps}")
                                clip = clip.set_fps(target_fps)
                            
                            # S'assurer que le clip n'a pas d'audio (√©viter les conflicts)
                            if hasattr(clip, 'audio') and clip.audio is not None:
                                clip = clip.without_audio()
                                st.info(f"üîá Audio retir√© du clip {i+1}")
                            
                            # Validation finale du clip harmonis√©
                            if clip is not None and hasattr(clip, 'duration') and clip.duration > 0:
                                # Test de frame pour s'assurer que le clip est fonctionnel
                                test_frame = clip.get_frame(0.1)
                                if test_frame is not None:
                                    clips.append(clip)
                                    st.success(f"‚úÖ Clip {i+1} harmonis√© et valid√© (FPS: {clip.fps})")
                                else:
                                    st.warning(f"‚ö†Ô∏è Clip {i+1} retourne frame None apr√®s harmonisation")
                                    clip.close()
                            else:
                                st.warning(f"‚ö†Ô∏è Clip {i+1} invalide apr√®s harmonisation")
                                if clip:
                                    clip.close()
                                    
                        except Exception as e:
                            st.error(f"‚ùå Erreur harmonisation clip {i+1}: {str(e)}")
                            if clip:
                                clip.close()
                    else:
                        st.warning(f"‚ö†Ô∏è Clip {i+1} invalide apr√®s conversion")
                except Exception as e:
                    st.error(f"‚ùå Erreur conversion clip {i+1}: {str(e)}")
                    if 'clip' in locals() and clip:
                        try:
                            clip.close()
                        except:
                            pass
                
                # Afficher les infos
                face_indicator = "üë§" if segment.get('has_target_face', False) else ""
                text_indicator = "üìù" if avoid_text and text_net is not None else ""
                st.info(f"üìπ Clip {i+1}: {segment['start']:.1f}s - {segment['end']:.1f}s (Score: {segment['score']:.0f}) {face_indicator} {text_indicator}")
                
        except Exception as e:
            st.warning(f"Impossible d'extraire le clip {i+1}: {str(e)}")
    
    return clips

def add_logo_overlay(
    video: VideoFileClip,
    logo_path: str,
    position: str = "Haut gauche",
    size_percent: int = 20,
    opacity: float = 0.5,
    margin: int = 40,
    vertical_position: int = 10
) -> VideoFileClip:
    """
    Ajoute un logo en overlay sur la vid√©o
    
    Args:
        video: Vid√©o de base
        logo_path: Chemin du logo
        position: Position du logo
        size_percent: Taille en % de la largeur
        opacity: Opacit√© du logo
        margin: Marge horizontale
        vertical_position: Position verticale
    
    Returns:
        VideoFileClip: Vid√©o avec logo
    """
    try:
        # Charger et redimensionner le logo
        logo_img = Image.open(logo_path)
        video_width = VIDEO_FORMAT['width']
        logo_width = int(video_width * size_percent / 100)
        logo_height = int(logo_img.height * (logo_width / logo_img.width))
        
        # Cr√©er le clip du logo
        logo_clip = ImageClip(logo_path).resize((logo_width, logo_height))
        logo_clip = logo_clip.set_duration(video.duration)
        logo_clip = logo_clip.set_opacity(opacity)
        
        # Positionner le logo
        if position == "Haut gauche":
            logo_clip = logo_clip.set_position((margin, vertical_position))
        elif position == "Haut droite":
            logo_clip = logo_clip.set_position((video_width - logo_width - margin, vertical_position))
        else:  # Haut centre
            logo_clip = logo_clip.set_position(((video_width - logo_width) // 2, vertical_position))
        
        # Composer
        video = CompositeVideoClip([video, logo_clip])
        st.success("‚úÖ Logo ajout√© en overlay!")
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Impossible d'ajouter le logo: {str(e)}")
    
    return video

def add_audio_to_video(
    video: VideoFileClip,
    audio_path: str,
    volume: float = 1.0,
    fade_in: float = 1.0,
    fade_out: float = 1.0,
    adapt_to_audio: bool = False,
    extra_seconds: int = 0
) -> VideoFileClip:
    """
    Ajoute une piste audio √† la vid√©o
    
    Args:
        video: Vid√©o de base
        audio_path: Chemin de l'audio
        volume: Volume de l'audio
        fade_in: Dur√©e du fondu d'entr√©e
        fade_out: Dur√©e du fondu de sortie
        adapt_to_audio: Adapter la dur√©e de la vid√©o √† l'audio
        extra_seconds: Secondes suppl√©mentaires apr√®s l'audio
    
    Returns:
        VideoFileClip: Vid√©o avec audio
    """
    try:
        # Charger l'audio
        audio_clip = AudioFileClip(audio_path)
        
        # Ajuster le volume
        audio_clip = audio_clip.volumex(volume)
        
        # Appliquer les fondus
        if fade_in > 0:
            audio_clip = audio_clip.audio_fadein(fade_in)
        if fade_out > 0:
            audio_clip = audio_clip.audio_fadeout(fade_out)
        
        # G√©rer la dur√©e
        video_duration = video.duration
        audio_duration = audio_clip.duration
        
        if adapt_to_audio:
            target_duration = audio_duration + extra_seconds
            
            if video_duration < target_duration:
                # Boucler la vid√©o
                n_loops = int(target_duration / video_duration) + 1
                video_clips = [video] * n_loops
                looped_video = concatenate_videoclips(video_clips)
                video = looped_video.subclip(0, target_duration)
                st.info(f"üîÑ Vid√©o ajust√©e √† {target_duration:.1f}s")
            elif video_duration > target_duration:
                # Couper la vid√©o
                video = video.subclip(0, target_duration)
                st.info(f"‚úÇÔ∏è Vid√©o coup√©e √† {target_duration:.1f}s")
        else:
            # Adapter l'audio √† la vid√©o
            if audio_clip.duration > video_duration:
                audio_clip = audio_clip.subclip(0, video_duration)
                st.info("‚úÇÔ∏è Audio coup√© √† la dur√©e de la vid√©o")
        
        # Attacher l'audio
        video = video.set_audio(audio_clip)
        st.success("‚úÖ Audio ajout√© avec succ√®s!")
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Impossible d'ajouter l'audio: {str(e)}")
        video = video.without_audio()
    
    return video

def create_final_video(
    clips: List[VideoFileClip],
    output_path: str,
    shuffle: bool = True,
    smart_shuffle: bool = True,
    clips_by_video: Optional[Dict[int, List[VideoFileClip]]] = None,
    logo_config: Optional[Dict] = None,
    audio_config: Optional[Dict] = None,
    tagline_path: Optional[str] = None,
    output_duration: Optional[float] = None
) -> bool:
    """
    Cr√©e la vid√©o finale √† partir des clips (optimis√© pour Railway)
    
    Args:
        clips: Liste des clips
        output_path: Chemin de sortie
        shuffle: M√©langer les clips
        smart_shuffle: M√©lange intelligent
        clips_by_video: Clips group√©s par vid√©o
        logo_config: Configuration du logo
        audio_config: Configuration audio
        tagline_path: Chemin de la tagline
        output_duration: Dur√©e souhait√©e
    
    Returns:
        bool: True si succ√®s
    """
    import gc  # Garbage collector pour lib√©rer la m√©moire
    
    try:
        # OPTIMISATIONS SP√âCIFIQUES RAILWAY
        if IS_RAILWAY:
            st.warning("üöÇ Mode Railway d√©tect√© - Optimisations m√©moire activ√©es")
            
            # Limiter drastiquement les clips pour Railway
            MAX_CLIPS_RAILWAY = 6  # R√©duit de 10 √† 6
            if len(clips) > MAX_CLIPS_RAILWAY:
                st.warning(f"‚ö†Ô∏è Limitation Railway: {MAX_CLIPS_RAILWAY} clips max pour √©viter l'OOM")
                clips = clips[:MAX_CLIPS_RAILWAY]
            
            # Forcer la lib√©ration m√©moire sur Railway
            import gc
            gc.collect()
            st.info("üßπ Nettoyage m√©moire Railway effectu√©")
        else:
            st.info("üíª Mode local d√©tect√© - Traitement standard")
            
            # Mode local: plus de clips possibles
            MAX_CLIPS_LOCAL = 10
            if len(clips) > MAX_CLIPS_LOCAL:
                st.info(f"‚ÑπÔ∏è Limitation locale: {MAX_CLIPS_LOCAL} clips max")
                clips = clips[:MAX_CLIPS_LOCAL]
        
        # M√©langer les clips si demand√©
        if smart_shuffle and clips_by_video and len(clips_by_video) > 1:
            clips = smart_shuffle_clips(clips_by_video)
            st.info("ü§ñ M√©lange intelligent appliqu√©")
        elif shuffle:
            random.shuffle(clips)
            st.info("üîÄ Clips m√©lang√©s al√©atoirement")
        
        # Valider et optimiser les clips
        st.info("üîç Validation des clips...")
        valid_clips = []
        for i, clip in enumerate(clips):
            # V√©rifier que le clip est valide
            if clip is None:
                st.warning(f"‚ö†Ô∏è Clip {i+1} est None, ignor√©")
                continue
            
            try:
                # Tester l'acc√®s au clip
                if hasattr(clip, 'duration') and clip.duration > 0:
                    # S'assurer que le clip n'a pas d'audio (√©conomie m√©moire)
                    if hasattr(clip, 'audio') and clip.audio is not None:
                        clip = clip.without_audio()
                    valid_clips.append(clip)
                    st.success(f"‚úÖ Clip {i+1} valid√© ({clip.duration:.1f}s)")
                else:
                    st.warning(f"‚ö†Ô∏è Clip {i+1} invalide (dur√©e: {getattr(clip, 'duration', 'N/A')})")
                    if clip:
                        clip.close()
            except Exception as e:
                st.error(f"‚ùå Erreur validation clip {i+1}: {str(e)}")
                if clip:
                    try:
                        clip.close()
                    except:
                        pass
        
        if not valid_clips:
            st.error("‚ùå Aucun clip valide trouv√©!")
            return False
            
        st.info(f"‚úÖ {len(valid_clips)} clips valides sur {len(clips)}")
        optimized_clips = valid_clips
        
        # Force garbage collection
        gc.collect()
        
        # Validation approfondie des clips avant concat√©nation
        st.info("üîß Validation approfondie des clips pour concat√©nation...")
        concat_ready_clips = []
        
        for i, clip in enumerate(optimized_clips):
            try:
                st.info(f"üîç Test concat√©nation clip {i+1}/{len(optimized_clips)}...")
                
                # Tests approfondis
                if not hasattr(clip, 'get_frame') or not hasattr(clip, 'duration'):
                    st.error(f"‚ùå Clip {i+1}: attributs manquants")
                    continue
                
                # Test d'acc√®s √† plusieurs frames
                test_times = [0, min(0.5, clip.duration/2), min(1.0, clip.duration-0.1)]
                frame_ok = True
                
                for test_time in test_times:
                    if test_time < 0 or test_time >= clip.duration:
                        continue
                    try:
                        frame = clip.get_frame(test_time)
                        if frame is None:
                            st.error(f"‚ùå Clip {i+1}: frame None √† t={test_time:.1f}s")
                            frame_ok = False
                            break
                    except Exception as e:
                        st.error(f"‚ùå Clip {i+1}: erreur frame t={test_time:.1f}s - {str(e)}")
                        frame_ok = False
                        break
                
                if frame_ok:
                    # Test de preview pour s'assurer que MoviePy peut g√©rer le clip
                    try:
                        preview = clip.subclip(0, min(0.1, clip.duration))
                        preview.close()
                        concat_ready_clips.append(clip)
                        st.success(f"‚úÖ Clip {i+1} pr√™t pour concat√©nation")
                    except Exception as e:
                        st.error(f"‚ùå Clip {i+1}: √©chec test preview - {str(e)}")
                        clip.close()
                else:
                    clip.close()
                    
            except Exception as e:
                st.error(f"‚ùå Erreur validation clip {i+1}: {str(e)}")
                if clip:
                    clip.close()
        
        if not concat_ready_clips:
            st.error("‚ùå Aucun clip valide pour la concat√©nation!")
            return False
            
        st.info(f"‚úÖ {len(concat_ready_clips)}/{len(optimized_clips)} clips pr√™ts pour concat√©nation")
        
        # STRAT√âGIE DE CONCAT√âNATION ADAPTATIVE
        if IS_RAILWAY:
            # Railway: Groupes tr√®s petits + m√©thode chain
            GROUP_SIZE = 2
            CONCAT_METHOD = "chain" 
            st.info("üöÇ Assemblage Railway (groupes de 2, m√©thode chain)...")
        else:
            # Local: Groupes plus gros + m√©thode compose
            GROUP_SIZE = 5
            CONCAT_METHOD = "compose"
            st.info("üíª Assemblage local optimis√©...")
        
        try:
            if len(concat_ready_clips) > GROUP_SIZE:
                # Traiter par groupes adapt√©s √† l'environnement
                temp_videos = []
                for i in range(0, len(concat_ready_clips), GROUP_SIZE):
                    group = concat_ready_clips[i:i+GROUP_SIZE]
                    st.info(f"üîó Concat√©nation groupe {i//GROUP_SIZE + 1}: {len(group)} clips")
                    
                    if IS_RAILWAY:
                        # Railway: Nettoyage m√©moire entre chaque groupe
                        gc.collect()
                    
                    # M√©thode de concat√©nation adapt√©e √† l'environnement
                    try:
                        temp_video = concatenate_videoclips(group, method=CONCAT_METHOD)
                        temp_videos.append(temp_video)
                        st.success(f"‚úÖ Groupe {i//GROUP_SIZE + 1} assembl√©")
                        
                        if IS_RAILWAY:
                            # Railway: Lib√©ration agressive de m√©moire
                            gc.collect()
                            
                    except Exception as e:
                        st.error(f"‚ùå Erreur groupe {i//GROUP_SIZE + 1}: {str(e)}")
                        # Fallback: essayer un par un
                        for j, single_clip in enumerate(group):
                            try:
                                if IS_RAILWAY:
                                    # Railway: Cr√©er un clip temporaire minimal
                                    mini_clip = single_clip.subclip(0, min(single_clip.duration, 10))
                                    temp_videos.append(mini_clip)
                                    st.warning(f"üöÇ Clip {i+j+1} ajout√© en mode Railway (max 10s)")
                                else:
                                    temp_videos.append(single_clip)
                                    st.warning(f"‚ö†Ô∏è Clip {i+j+1} ajout√© individuellement")
                            except Exception as e2:
                                st.error(f"‚ùå Impossible d'ajouter clip {i+j+1}: {str(e2)}")
                    
                    # Lib√©rer la m√©moire
                    gc.collect()
                
                if not temp_videos:
                    st.error("‚ùå Aucun groupe n'a pu √™tre assembl√©")
                    return False
                
                # Assembler les vid√©os temporaires
                st.info(f"üîó Assemblage final de {len(temp_videos)} groupes...")
                
                if IS_RAILWAY:
                    # Railway: M√©thode la plus simple
                    final_video = concatenate_videoclips(temp_videos, method="chain")
                    st.info("üöÇ Assemblage final Railway (chain)")
                else:
                    # Local: Utiliser chain au lieu de compose pour plus de stabilit√©
                    final_video = concatenate_videoclips(temp_videos, method="chain") 
                    st.info("üíª Assemblage final local (chain - stable)")
                
                # Lib√©rer les vid√©os temporaires
                for temp in temp_videos:
                    if hasattr(temp, 'close'):
                        temp.close()
            else:
                st.info(f"üîó Concat√©nation directe de {len(concat_ready_clips)} clips...")
                final_video = concatenate_videoclips(concat_ready_clips, method=CONCAT_METHOD)
                
                if IS_RAILWAY:
                    st.info("üöÇ Concat√©nation directe Railway")
                else:
                    st.info("üíª Concat√©nation directe locale")
                
        except Exception as e:
            st.error(f"‚ùå ERREUR CONCAT√âNATION: {str(e)}")
            st.warning("üö® Tentative de sauvegarde d'urgence...")
            
            # Fallback: prendre seulement le premier clip valide
            if concat_ready_clips:
                st.warning("‚ö†Ô∏è Sauvegarde du premier clip seulement")
                final_video = concat_ready_clips[0]
                for clip in concat_ready_clips[1:]:
                    clip.close()
            else:
                return False
        
        # VALIDATION CRITIQUE de la vid√©o finale apr√®s concat√©nation
        try:
            if final_video is None:
                st.error("‚ùå ERREUR FATALE: final_video est None apr√®s concat√©nation")
                return False
            
            if not hasattr(final_video, 'get_frame'):
                st.error("‚ùå ERREUR FATALE: final_video n'a pas de m√©thode get_frame")
                return False
            
            # Test d'acc√®s √† une frame pour valider
            test_frame = final_video.get_frame(0.1)
            if test_frame is None:
                st.error("‚ùå ERREUR FATALE: final_video.get_frame(0.1) retourne None")
                return False
            
            st.success(f"‚úÖ Vid√©o finale VALID√âE apr√®s concat√©nation ({final_video.duration:.1f}s)")
            
        except Exception as e:
            st.error(f"‚ùå ERREUR FATALE: final_video non fonctionnelle: {str(e)}")
            return False
        
        # Ajuster la dur√©e si n√©cessaire
        if output_duration and not (audio_config and audio_config.get('adapt_to_audio')):
            if final_video.duration > output_duration:
                final_video = final_video.subclip(0, output_duration)
                st.info(f"‚úÇÔ∏è Vid√©o coup√©e √† {output_duration}s")
        
        # Ajouter le logo
        if logo_config:
            final_video = add_logo_overlay(final_video, **logo_config)
        
        # Ajouter l'audio
        if audio_config:
            final_video = add_audio_to_video(final_video, **audio_config)
        else:
            final_video = final_video.without_audio()
        
        # Ajouter la tagline
        if tagline_path:
            final_video = add_tagline(final_video, tagline_path)
        
        # ENCODAGE ADAPTATIF LOCAL vs RAILWAY
        if IS_RAILWAY:
            st.info("üöÇ Encodage Railway (optimis√© m√©moire)...")
            encoding_params = {
                'codec': 'libx264',
                'fps': VIDEO_FORMAT['fps'],
                'preset': 'ultrafast',  # Plus rapide = moins de RAM
                'threads': 2,  # R√©duit pour Railway
                'logger': None,  # Pas de logs pour √©conomiser RAM
                'write_logfile': False,
                'bitrate': '3000k',  # Compromise qualit√©/taille pour Railway
            }
            
            # R√©solution adapt√©e Railway
            if final_video.duration > 30:
                encoding_params['bitrate'] = '2000k'
                st.warning("üöÇ Vid√©o longue: bitrate r√©duit sur Railway")
        else:
            st.info("üíª Encodage local (haute qualit√©)...")
            encoding_params = {
                'codec': 'libx264',
                'fps': VIDEO_FORMAT['fps'],
                'preset': 'medium',  # Meilleure qualit√© en local
                'threads': 8,  # Plus de threads en local
                'logger': 'bar',
                'write_logfile': False,
                'bitrate': VIDEO_FORMAT['bitrate'],  # Pleine qualit√©
            }
            
            # Qualit√© maximale pour vid√©os courtes en local
            if final_video.duration <= 60:
                encoding_params['preset'] = 'slow'  # Qualit√© maximale
                encoding_params['bitrate'] = '8000k'  # Tr√®s haute qualit√©
                st.info("üéØ Vid√©o courte: qualit√© maximale en local")
        
        if final_video.audio is not None:
            if IS_RAILWAY:
                encoding_params['audio_codec'] = 'aac'
                encoding_params['audio_bitrate'] = '96k'  # Audio comprim√© Railway
            else:
                encoding_params['audio_codec'] = 'aac'
                encoding_params['audio_bitrate'] = '192k'  # Audio HD local
        else:
            encoding_params['audio'] = False
            
        # Progress tracking
        progress_bar = st.progress(0)
        progress_text = st.empty()
        
        def progress_callback(frame, total_frames):
            if total_frames > 0:
                progress = int((frame / total_frames) * 100)
                progress_bar.progress(progress)
                progress_text.text(f"Encodage: {progress}%")
        
        # √âcrire la vid√©o
        final_video.write_videofile(
            output_path,
            **encoding_params,
            temp_audiofile=output_path.replace('.mp4', '_temp_audio.m4a')
        )
        
        progress_bar.progress(100)
        progress_text.text("‚úÖ Encodage termin√©!")
        
        # Lib√©rer la m√©moire
        for clip in clips:
            if hasattr(clip, 'close'):
                try:
                    clip.close()
                except:
                    pass
        
        if hasattr(final_video, 'close'):
            try:
                final_video.close()
            except:
                pass
        
        return True
        
    except Exception as e:
        st.error(f"Erreur lors de la cr√©ation de la vid√©o: {str(e)}")
        st.error(f"D√©tails de l'erreur: {type(e).__name__}")
        # Nettoyer en cas d'erreur
        try:
            for clip in clips:
                if hasattr(clip, 'close'):
                    clip.close()
        except:
            pass
        return False

def smart_shuffle_clips(clips_by_video: Dict[int, List[VideoFileClip]]) -> List[VideoFileClip]:
    """
    M√©lange intelligent en alternant entre les vid√©os
    
    Args:
        clips_by_video: Clips group√©s par vid√©o
    
    Returns:
        List[VideoFileClip]: Clips m√©lang√©s
    """
    shuffled_clips = []
    
    # Cr√©er des listes de clips par vid√©o
    video_clip_lists = list(clips_by_video.values())
    
    # M√©langer chaque liste individuellement
    for clip_list in video_clip_lists:
        random.shuffle(clip_list)
    
    # Alterner entre les vid√©os
    max_clips = max(len(clips) for clips in video_clip_lists)
    
    for i in range(max_clips):
        for video_clips in video_clip_lists:
            if i < len(video_clips):
                shuffled_clips.append(video_clips[i])
    
    return shuffled_clips

def add_tagline(video: VideoFileClip, tagline_path: str) -> VideoFileClip:
    """
    Ajoute une vid√©o tagline √† la fin
    
    Args:
        video: Vid√©o principale
        tagline_path: Chemin de la tagline
    
    Returns:
        VideoFileClip: Vid√©o avec tagline
    """
    try:
        st.info("üè∑Ô∏è Ajout de la vid√©o tagline...")
        tagline_clip = VideoFileClip(tagline_path)
        
        # Redimensionner au format 9:16
        tagline_clip = resize_and_center_vertical(tagline_clip, use_lanczos=False)
        
        # Si la vid√©o a un audio, garder la tagline sans audio
        if video.audio is not None:
            tagline_clip = tagline_clip.without_audio()
        
        # Concat√©ner
        final_video = concatenate_videoclips([video, tagline_clip], method="compose")
        st.success(f"‚úÖ Tagline ajout√©e ({tagline_clip.duration:.1f}s)")
        
        return final_video
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Impossible d'ajouter la tagline: {str(e)}")
        return video